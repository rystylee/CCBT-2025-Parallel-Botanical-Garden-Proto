# 要件定義書

## 1. プロジェクト概要

### 1.1 プロジェクト名
CCBT-2025-Parallel-Botanical-Garden-Proto

### 1.2 目的
M5Stack LLM Compute Kit上で動作する分散型音声対話システムを構築し、複数のBotanical Intelligence（BI）デバイスがOSC（Open Sound Control）プロトコル経由で相互に通信しながら、StackFlowを使用したLLM（大規模言語モデル）による協調的な詩的テキスト生成とTTS（Text-to-Speech）による音声出力を行う。各デバイスは独立したサイクルで動作し、人間の入力と他のBIデバイスからの入力を受け取りながら、短い詩的表現を生成し続ける。

### 1.3 対象ユーザー
- アーティスト・クリエイター
- 音楽制作者
- インタラクティブインスタレーション制作者
- AI研究者

### 1.4 動作環境
- **ハードウェア**: M5Stack LLM630 Compute Kit
- **OS**: Ubuntu (ARM64アーキテクチャ)
- **言語**: Python 3.10以上
- **ネットワーク**: Wi-Fi接続必須
- **通信プロトコル**: OSC (UDP), TCP

---

## 2. 機能要件

### 2.0 BIデバイス動作モード

#### 2.0.1 デバイスタイプ
システムは2種類のBIデバイスタイプをサポート:

**1st BI（プライマリBI）**
- マイク入力（人間の声）を受け付ける
- 他のBIデバイスからの信号も受け付ける
- 入力データ: `{timestamp, text(from human), text(from BI)}`

**2nd BI（セカンダリBI）**
- 他のBIデバイスからの信号のみを受け付ける
- 人間の入力は受け付けない
- 入力データ: `{timestamp, text(from BI)}`

#### 2.0.2 動作サイクル
各BIデバイスは独立した4段階のサイクルで動作:

1. **入力受付期間（3秒）**
   - OSC経由で入力データを受け付ける（複数可）
   - 受信データにタイムスタンプが付与される
   - 1分以上古いデータは自動的に破棄される

2. **生成期間**
   - 採用された入力データを時系列順に連結
   - LLMで続きのテキストを生成（2~3トークン）

3. **出力期間**
   - 生成したテキストデータとタイムスタンプを次のBIデバイスへOSC送信
   - 全入力データ + 生成テキストをTTSで音声再生

4. **休息期間（1秒）**
   - 処理を行わず待機

→ サイクル1に戻る

### 2.1 LLM推論機能

#### 2.1.1 基本機能
- OSCメッセージで受信したテキストを入力として、詩的な短文（2~3トークン）を生成する
- StackFlow LLM APIを使用したオンデバイス推論（クラウド不要）
- ストリーミング形式でのトークン単位生成
- **最大3トークンまでの出力対応**（新仕様）
- 複数入力データの時系列順連結処理

#### 2.1.2 多言語対応
サポート言語:
- 日本語（ja）
- 英語（en）
- 中国語（zh）
- フランス語（fr）

各言語に特化した:
- システムプロンプト
- 翻訳プロンプト
- インストラクションプロンプト

#### 2.1.3 翻訳機能
- 入力テキストが異なる言語の場合、設定言語に自動翻訳
- オフライン翻訳ライブラリ（argostranslate）を使用
- Google翻訳APIのフォールバック対応

#### 2.1.4 プロンプト機構
- **システムプロンプト**: LLMに詩人ロールを付与
- **インストラクションプロンプト**: 2~3トークンの短い詩的表現を生成
- **ソフトプリフィックス**: bf16形式のプリフィックスチューニング対応（オプション）

#### 2.1.5 モデル設定
デフォルトモデル:
- `qwen2.5-0.5B-prefill-20e`（日本語、英語、中国語、フランス語）

### 2.2 TTS音声合成機能

#### 2.2.1 基本機能
- StackFlow TTS APIを使用した音声合成
- MeloTTSモデルによる高品質音声生成
- PCMフォーマットでのストリーム再生
- 自動音量調整（デフォルト15%）

#### 2.2.2 対応モデル
- `melotts-ja-jp`（日本語）
- `melotts-en-us`（英語）
- `melotts-zh-cn`（中国語）

#### 2.2.3 オーディオ設定
- 再生カード選択: カード0、デバイス1
- 音量制御: 0.0〜1.0（デフォルト0.15）
- リアルタイムPCMストリーム再生

### 2.3 OSC通信機能

#### 2.3.1 OSCサーバー（受信）
- **プロトコル**: UDP
- **デフォルトポート**: 8000
- **非同期処理**: asyncioベース
- **入力バッファリング**: 3秒間の入力を蓄積

#### 2.3.2 対応OSCアドレス

| OSCアドレス | 引数 | 機能 | 実装状態 |
|------------|------|------|---------|
| `/bi/input` | timestamp, text, source_type, lang | BI入力データ受付（人間・BI両方） | ✅ 実装済み |
| `/bi/start` | なし | BIサイクル開始 | ✅ 実装済み |
| `/bi/stop` | なし | BIサイクル停止 | ✅ 実装済み |
| `/bi/status` | なし | BIステータス取得 | ✅ 実装済み |

#### 2.3.3 OSCクライアント（送信）
- 設定ファイルで指定された送信先デバイスへのメッセージ送信
- タイムスタンプ付きメッセージの送信
- 複数ターゲットデバイスへの同時送信対応
- 将来的にExcelファイルからのトポロジー設定読み込み対応予定

### 2.4 StackFlow通信機能

#### 2.4.1 TCP接続
- **接続先**: `localhost:10001`
- **プロトコル**: JSON over TCP（改行区切り）
- **エンコーディング**: UTF-8

#### 2.4.2 通信フロー
1. TCP接続確立
2. セッションセットアップ（LLM/TTS初期化）
3. 推論リクエスト送信
4. ストリーミングレスポンス受信
5. セッション終了

#### 2.4.3 エラーハンドリング
- 接続エラー時の再接続
- タイムアウト処理
- 異常レスポンスのログ記録

### 2.5 設定管理機能

#### 2.5.1 設定ファイル
ファイルパス: `config/config.json`

設定項目:
- **network**: デバイス名、IPアドレス
- **device**: デバイスタイプ（"1st_BI" or "2nd_BI"）
- **cycle**: サイクル設定
  - `receive_duration`: 入力受付期間（秒）
  - `rest_duration`: 休息期間（秒）
  - `max_data_age`: データ有効期限（秒）
- **targets**: 送信先デバイスリスト `[{host, port}, ...]`
- **osc**: 送受信ポート
- **common**: 言語設定
- **stack_flow_llm**: LLM設定（max_tokens: 3）
- **stack_flow_tts**: TTS設定
- **system**: デバッグモード、ログレベル

#### 2.5.2 実行時パラメータ
コマンドライン引数:
- `--config`: 設定ファイルパス（デフォルト: `config/config.json`）

---

## 3. 非機能要件

### 3.1 性能要件
- **サイクル時間**: 入力受付3秒 + 生成期間 + 出力期間 + 休息1秒
- **LLM推論速度**: 2~3トークン生成を高速に（目標: 1秒以内）
- **TTS生成速度**: 1秒以内に音声再生開始
- **タイムスタンプ精度**: ミリ秒単位でのタイムスタンプ管理
- **データフィルタリング**: 1分以上古いデータの即座な破棄

### 3.2 信頼性要件
- **稼働率**: 継続動作（サイクルの無限ループ）
- **エラーリカバリー**: StackFlow接続エラー時の自動再接続
- **ログ記録**: loguru使用による詳細ログ出力
- **状態管理**: 各サイクル状態の明確な管理

### 3.3 拡張性要件
- **言語追加**: 新規言語の容易な追加（LLM_SETTINGSに追加）
- **モデル切り替え**: 設定ファイルでのモデル変更
- **トポロジー拡張**: Excelファイルからのネットワークトポロジー読み込み（将来実装）
- **デバイス追加**: 設定ファイルで送信先デバイスの追加が容易

### 3.4 保守性要件
- **コード品質**: モジュール化されたアーキテクチャ
- **テストスクリプト**: 各機能の単体テスト用スクリプト
- **ドキュメント**: README、コメント、型ヒント

### 3.5 セキュリティ要件
- **ネットワーク**: ローカルネットワーク内のみでの動作
- **認証**: 現時点では認証なし（ローカル環境前提）

---

## 4. システム要件

### 4.1 ソフトウェア依存関係

#### 4.1.1 システムパッケージ
- git
- curl
- jq
- tmux
- adb（開発時）

#### 4.1.2 Pythonライブラリ
| ライブラリ | バージョン | 用途 |
|-----------|----------|------|
| loguru | ≥0.7.3 | ロギング |
| python-osc | ≥1.9.3 | OSCプロトコル実装 |
| argostranslate | ≥1.9.6 | オフライン翻訳 |
| googletrans | ≥4.0.2 | Google翻訳API |
| openai | ≥1.109.1 | OpenAI API（将来的な拡張用） |

#### 4.1.3 StackFlowモデル
- `llm-model-qwen2.5-1.5b-ax630c`
- `llm-model-llama3.2-1b-prefill-ax630c`
- `llm-model-melotts-ja-jp`
- `llm-model-melotts-en-us`
- `llm-model-melotts-zh-cn`

#### 4.1.4 翻訳パッケージ
- `en_ja`（英日）
- `ja_en`（日英）
- `zh_ja`（中日）
- `fr_ja`（仏日）

### 4.2 ハードウェア要件
- **CPU**: ARM64アーキテクチャ
- **メモリ**: 最低2GB RAM
- **ストレージ**: 最低8GB（モデル含む）
- **オーディオ**: スピーカーまたはヘッドフォン出力

### 4.3 ネットワーク要件
- **Wi-Fi接続**: 必須（OSC通信用）
- **IPアドレス**: 固定IPまたはDHCP
- **ポート**: UDP 8000（OSC受信）

---

## 5. インターフェース要件

### 5.1 OSC入力インターフェース

#### 5.1.1 `/bi/input` エンドポイント（主要）
```python
OSC Address: /bi/input
Arguments:
  - [0]: タイムスタンプ (float) - UNIX時間（秒）
  - [1]: テキスト (str) - 入力テキスト
  - [2]: ソースタイプ (str) - "human" または "BI"
  - [3]: 言語コード (str) - "ja", "en", "zh", "fr"のいずれか

Example:
  /bi/input 1707234567.123 "こんにちは" "human" "ja"
  /bi/input 1707234568.456 "世界" "BI" "ja"

Note:
  - 2nd BIデバイスは source_type="human" のメッセージを無視
  - タイムスタンプが60秒以上古いメッセージは自動破棄
```

#### 5.1.2 `/bi/start` エンドポイント
```python
OSC Address: /bi/start
Arguments: なし

機能: BIサイクルを開始する

Example:
  /bi/start
```

#### 5.1.3 `/bi/stop` エンドポイント
```python
OSC Address: /bi/stop
Arguments: なし

機能: BIサイクルを停止する

Example:
  /bi/stop
```

#### 5.1.4 `/bi/status` エンドポイント
```python
OSC Address: /bi/status
Arguments: なし

機能: 現在のBIステータス（状態、バッファサイズ等）を取得

Example:
  /bi/status
```


### 5.2 OSC出力インターフェース

#### 5.2.1 BI出力メッセージ（他のBIへの循環送信）
```python
OSC Address: /bi/input
Arguments:
  - [0]: タイムスタンプ (float) - UNIX時間（秒）
  - [1]: 生成テキスト (str) - LLMが生成した2~3トークン
  - [2]: ソースタイプ (str) - "BI"（他のBIからの出力であることを示す）
  - [3]: 言語コード (str)

Example:
  /bi/input 1707234571.789 "世界よ" "BI" "ja"

Note:
  - 送信先は config.json の targets に設定されたデバイス
  - タイムスタンプは送信時の現在時刻
  - source_type は常に "BI"（他のBIデバイスからの出力として送信）
  - 受信側の2nd_BIデバイスは source_type="BI" のメッセージのみを受け付ける
```

### 5.3 StackFlow LLM APIインターフェース

#### 5.3.1 セットアップリクエスト
```json
{
  "request_id": "llm_001",
  "work_id": "llm",
  "action": "setup",
  "object": "llm.utf-8.stream",
  "data": {
    "model": "qwen2.5-0.5B-prefill-20e",
    "response_format": "llm.utf-8.stream",
    "max_token_len": 128,
    "prompt": "システムプロンプト"
  }
}
```

#### 5.3.2 推論リクエスト
```json
{
  "request_id": "llm_002",
  "work_id": "llm_work_abc123",
  "action": "inference",
  "data": {
    "delta": "インストラクションプロンプト + 入力テキスト",
    "soft_prefix": {
      "len": 1,
      "data_b64": "base64エンコードされたbf16データ"
    }
  }
}
```

#### 5.3.3 ストリーミングレスポンス
```json
{
  "request_id": "llm_002",
  "work_id": "llm_work_abc123",
  "data": {
    "delta": "生成されたトークン",
    "finish": false
  }
}
```

### 5.4 StackFlow TTS APIインターフェース

#### 5.4.1 オーディオセットアップリクエスト
```json
{
  "request_id": "audio_001",
  "work_id": "tts",
  "action": "setup",
  "object": "audio.playback",
  "data": {
    "playcard": 0,
    "playdevice": 1,
    "playVolume": 0.15
  }
}
```

#### 5.4.2 TTSセットアップリクエスト
```json
{
  "request_id": "tts_001",
  "work_id": "tts",
  "action": "setup",
  "object": "text2speech.inference.stream",
  "data": {
    "model": "melotts-ja-jp",
    "response_format": "tts.pcm.stream"
  }
}
```

#### 5.4.3 推論リクエスト
```json
{
  "request_id": "tts_002",
  "work_id": "tts_work_abc123",
  "action": "inference",
  "data": {
    "text": "宙に舞う無数の星空。"
  }
}
```

---

## 6. データ要件

### 6.1 設定データ
- **フォーマット**: JSON
- **エンコーディング**: UTF-8
- **バックアップ**: Git管理

### 6.2 ログデータ
- **ライブラリ**: loguru
- **出力先**: 標準出力、ファイル（オプション）
- **ログレベル**: DEBUG, INFO, WARNING, ERROR

### 6.3 一時データ
- **StackFlowセッションID**: メモリ上で管理
- **生成テキストキャッシュ**: なし（リアルタイム処理）

---

## 7. 制約事項

### 7.1 技術的制約
- M5Stack LLM Compute Kit上でのみ動作
- StackFlow APIに依存（他のLLM/TTSサービスは未対応）
- オフライン動作（翻訳モデルがインストール済みの場合）

### 7.2 機能的制約
- LLM出力は最大128トークンまで
- TTS音声はリアルタイム再生のみ（ファイル保存なし）
- OSCプロトコルのみ対応（HTTP/WebSocket等は未対応）

### 7.3 運用上の制約
- 同時実行数は非同期処理により自動制御
- StackFlow APIの応答速度に依存
- 長時間稼働時のメモリリーク対策は未実装

---

## 8. 将来的な拡張要件

### 8.1 機能拡張
- [ ] HTTP APIサポート
- [ ] WebSocketによるリアルタイム通信
- [ ] 生成テキスト履歴の保存
- [ ] 音声ファイルのエクスポート機能
- [ ] ユーザー定義プロンプトテンプレート

### 8.2 モデル拡張
- [ ] より大きなLLMモデル対応（1.5B, 3B等）
- [ ] カスタムファインチューニングモデル対応
- [ ] 複数モデルの同時実行

### 8.3 インターフェース拡張
- [ ] GUI管理画面
- [ ] WebブラウザからのOSC送信インターフェース
- [ ] MIDI CC対応

### 8.4 パフォーマンス改善
- [ ] モデルキャッシュ機構
- [ ] バッチ推論対応
- [ ] GPU最適化

---

## 9. 受入基準

### 9.1 機能テスト
- [ ] OSCメッセージ送信で正常に詩が生成される
- [ ] TTS音声が正常に再生される
- [ ] 全対応言語で動作する
- [ ] エラー発生時に適切なログが出力される

### 9.2 性能テスト
- [ ] 1回の推論が5秒以内に完了する
- [ ] 連続10回の推論が安定して動作する
- [ ] 1時間の連続稼働でメモリリークがない

### 9.3 統合テスト
- [ ] test.pyからのOSC送信が正常に動作する
- [ ] 複数クライアントからの同時送信が正常に処理される

---

## 10. 参考資料

- M5Stack LLM Compute Kit ドキュメント
- StackFlow API仕様書
- OSC 1.0 プロトコル仕様
- MeloTTS モデルドキュメント
- argostranslate ライブラリドキュメント
